<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="HaloQuest">
  <meta name="keywords" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>HaloQuest</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!--<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>-->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">HaloQuest: A Visual Hallucination Dataset for Advancing Multimodal Reasoning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.zhecanwang.com/">Zhecan Wang</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a>Garrett Bingham</a><sup>2*</sup>,
            </span>
            <span class="author-block">
              <a>Adams Wei Yu</a><sup>2</sup>
            </span>
            <br>
            <span class="author-block">
              <a>Quoc V. Le</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a>Thang Luong</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a>Golnaz Ghiasi</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Columbia University,</span>
            <span class="author-block"><sup>2</sup>Google DeepMind</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2407.15680"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2407.15680"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ZhecanJamesWang/HaloQuest"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/google/haloquest/blob/main/HaloQuest_Colab.ipynb"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <image  src="static/images/teaser.png"/>
      <h2 class="subtitle has-text-centered">
        HaloQuest is a challenging evaluation benchmark and a training dataset
        aimed at mitigating hallucination in VLMs.
      </h2>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Hallucination has been a major problem for large language models and remains a critical challenge when it comes to multimodality in which vision-language models (VLMs) have to deal with not just textual but also visual inputs. Despite rapid progress in VLMs, resources for evaluating and addressing multimodal hallucination are limited and mostly focused on evaluation. This work introduces HaloQuest, a novel visual question answering dataset that captures various aspects of multimodal hallucination such as false premises, insufficient contexts, and visual challenges. A novel idea from HaloQuest is to leverage synthetic images, apart from real ones, to enable dataset creation at scale. With over 7.7K examples spanning across a wide variety of categories, HaloQuest was designed to be both a challenging benchmark for VLMs and a finetuning dataset for advancing multimodal reasoning. Our experiments reveal that current models struggle with HaloQuest, with all open-source VLMs achieving below 36% accuracy. On the other hand, fine-tuning on HaloQuest significantly reduces hallucination rates while preserving performance on standard reasoning tasks. Our results discover that benchmarking with generated images is highly correlated (r = 0.97) with real images. Last but not least, we propose a novel Auto-Eval mechanism that is highly correlated with human raters (r = 0.99) for evaluating VLMs. In sum, this work makes concrete strides towards understanding, evaluating, and mitigating hallucination in VLMs, serving as an important step towards more reliable multimodal AI systems in the future.            
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Dataset Description</h2>
      </div>
    </div>
    <!-- Summary -->
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">Summary</h2>
      <p>
        HaloQuest is a novel visual question answering (VQA) dataset that focuses on multimodal hallucination in vision-language models (VLMs). It contains over 7,748 examples with a combination of real and synthetically generated images, annotated with questions and answers designed to trigger and evaluate hallucinations.
      </p>
      
      <!-- Supported Tasks -->
      <h2 class="subtitle has-text-centered">Supported Tasks</h2>
      <p>
        HaloQuest supports tasks related to hallucination detection and reduction in VLMs, providing a challenging benchmark for Visual Question Answering. The dataset is useful for both evaluation and fine-tuning purposes, aiming to advance multimodal reasoning.
      </p>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Dataset Details</h2>
      </div>
    </div>
    <!-- Data Collection -->
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">Data Collection</h2>
      <p>
        HaloQuest includes a mix of real images from the Open Images dataset and synthetic images generated using Midjourney and Stable Diffusion. Images were curated based on interest and comprehensibility. Questions and answers were crafted by humans and large language models (LLMs), focusing on false premises, visually challenging questions, and questions with insufficient context.
      </p>
      <image  src="static/images/data-collection-pipeline.png"/>
      
      <!-- Data Instances -->
      <h2 class="subtitle has-text-centered">Data Instances</h2>
      <p>
        Example entries from HaloQuest include complex questions requiring nuanced reasoning and detailed answers. Below are some samples:
      </p>
      <image  src="static/images/example-image.png"/>

      <!-- Data Splits -->
      <h2 class="subtitle has-text-centered">Data Splits</h2>
      <p>The dataset is split into training and evaluation sets. The following table provides detailed statistics for each subset.</p>
      <table tabindex="0">
        <thead><tr>
        <th></th><th align="center">Real Images</th><th align="center">Synthetic Images</th><th align="center">False Premise Questions</th><th align="center">Visually Challenging Questions</th><th align="center">Insufficient Context Questions</th><th align="center">Total Entries</th></tr></thead>
        <tbody><tr><td>Train Set</td><td align="center">2985</td><td align="center">4155</td><td align="center">2698</td><td align="center">2973</td><td align="center">1469</td><td align="center">7140</td></tr><tr>
        <td>Eval Set</td><td align="center">217</td><td align="center">391</td><td align="center">304</td><td align="center">183</td><td align="center">121</td><td align="center">608</td></tr>
        <tr><td>Total</td><td align="center">3202</td><td align="center">4546</td><td align="center">3002</td><td align="center">3156</td><td align="center">1590</td><td align="center">7748</td>
        </tr>
        </tbody>
        </table>

    </div>
  </div>
</section>

<section>
  <div class="container"><div class="columns is-centered"><div class="column is-full has-text-centered content">
    <table id="leaderboard">
      <thead>
          <tr>
              <th colspan="2"></th>
              <th colspan="2">Overall</th>
              <th colspan="2">Generated</th>
              <th colspan="2">Real</th>
              <th colspan="2">False Premise</th>
              <th colspan="2">Visually Challenging</th>
              <th colspan="2">Insufficient Context</th>
          </tr>
      </thead>
      <thead id="secondHead">
          <tr>
              <th onclick="sortTable(0)" json_label="model">Model (#Param)</th>
              <th onclick="sortTable(1)" json_label="rank">Rank</th>

              <th onclick="sortTable(2)" json_label="overall_human">Human Eval</th>
              <th onclick="sortTable(3)" json_label="overall_auto">Auto-Eval</th>
              
              <th onclick="sortTable(4)" json_label="generated_human">Human Eval</th>
              <th onclick="sortTable(5)" json_label="generated_auto">Auto-Eval</th>
              <th onclick="sortTable(6)" json_label="real_human">Human Eval</th>
              <th onclick="sortTable(7)" json_label="real_auto">Auto-Eval</th>

              <th onclick="sortTable(8)" json_label="prem_human">Human Eval</th>
              <th onclick="sortTable(9)" json_label="prem_auto">Auto-Eval</th>
              <th onclick="sortTable(10)" json_label="vis_human">Human Eval</th>
              <th onclick="sortTable(11)" json_label="vis_auto">Auto-Eval</th>
              <th onclick="sortTable(12)" json_label="insuf_human">Human Eval</th>
              <th onclick="sortTable(13)" json_label="insuf_auto">Auto-Eval</th>
          </tr>
        </thead>
      <tbody>
      </tbody>
    </table>
  </div></div></div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Contact</h2>
        <div class="content has-text-justified">
          <p>For any questions about HaloQuest, please contact <a href= "olinzhecanwang@gmail.com">olinzhecanwang@gmail.com</a>.</p>
        </div>
      </div>
    </div>
  </div>    
</section>
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{wang2024haloquest,
      title={HaloQuest: A Visual Hallucination Dataset for Advancing Multimodal Reasoning},
      author={Wang, Zhecan and Bingham, Garrett and Yu, Adams and Le, Quoc and Luong, Thang and Ghiasi, Golnaz},
      journal={arXiv preprint arXiv:2407.15680},
      year={2024}
    }</code></pre>
  </div>
</section>



<footer class="footer">
  <div class="content has-text-centered">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is website adapted from <a
              href="https://nerfies.github.io/">Nerfies</a>,
            licensed under a
            <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
